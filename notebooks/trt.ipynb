{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30971cc",
   "metadata": {},
   "source": [
    "# Running DeepConsensus in TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef224e9b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash \n",
    "\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# pip install deepconsensus[gpu]==1.1.0 onnxruntime tensorrt pycuda tf2onnx gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ddf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fdf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f194b3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 15:35:02.037589: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 15:35:03.001996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 15:35:03.002079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 15:35:03.002090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "import colorama\n",
    "import numpy as np\n",
    "import random\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "from deepconsensus.models import model_configs\n",
    "from deepconsensus.models import model_utils\n",
    "from deepconsensus.models import data_providers\n",
    "from deepconsensus.utils import dc_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcb273",
   "metadata": {},
   "source": [
    "## Load the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276b3cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/checkpoint.data-00000-of-00001...\n",
      "Copying gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/checkpoint.index...\n",
      "Copying gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/params.json...\n",
      "/ [3 files][ 85.7 MiB/ 85.7 MiB]                                                \n",
      "Operation completed over 3 objects/85.7 MiB.                                     \n",
      "Copying gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/test/tf-test-00000-of-00500.tfrecord.gz...\n",
      "\\ [1 files][ 90.6 MiB/ 90.6 MiB]                                                \n",
      "Operation completed over 1 objects/90.6 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Download Model\n",
    "mkdir -p deepconsensus_model\n",
    "gsutil cp -r gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/* deepconsensus_model/\n",
    "# Download test data\n",
    "gsutil cp gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/test/tf-test-00000-of-00500.tfrecord.gz ./tf-test.tfrecord.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37dd22e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 15:35:10.758689: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-19 15:35:10.758731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: hcsa-dgx32gb\n",
      "2023-01-19 15:35:10.758741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: hcsa-dgx32gb\n",
      "2023-01-19 15:35:10.758840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.1\n",
      "2023-01-19 15:35:10.758871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n",
      "2023-01-19 15:35:10.758879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.65.1\n",
      "2023-01-19 15:35:10.759311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name.shape: (512, 1)\n",
      "label.shape: (512, 100)\n",
      "rows.shape: (512, 85, 100, 1)\n",
      "num_passes.shape: (512, 1)\n",
      "window_pos.shape: (512, 1)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'deepconsensus_model/checkpoint'\n",
    "params = model_utils.read_params_from_json(checkpoint_path=checkpoint_path)\n",
    "\n",
    "tfrecord_path = 'tf-test.tfrecord.gz'\n",
    "\n",
    "# Number of examples:\n",
    "batch_size = 512  #@param\n",
    "\n",
    "ds = data_providers.get_dataset(tfrecord_path,\n",
    "                                num_epochs=None,\n",
    "                                batch_size=batch_size,\n",
    "                                params=params,\n",
    "                                inference=False)\n",
    "\n",
    "# Just get one batch to inspect:\n",
    "for batch in ds.take(1):\n",
    "  break\n",
    "\n",
    "keys = ['name', 'label', 'rows', 'num_passes', 'window_pos']\n",
    "for key in keys:\n",
    "  print(f'{key}.shape: {batch[key].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975e7e7",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7debf0c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_only_learned_values_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " relative_position_embedding  multiple                 0         \n",
      "  (RelativePositionEmbedding                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_stack (EncoderStack  multiple                 7320200   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  1405      \n",
      "                                                                 \n",
      " softmax (Softmax)           multiple                  0         \n",
      "                                                                 \n",
      " bases_embedding (ModifiedOn  multiple                 40        \n",
      " DeviceEmbedding)                                                \n",
      "                                                                 \n",
      " pw_embedding (ModifiedOnDev  multiple                 2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " ip_embedding (ModifiedOnDev  multiple                 2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " sn_embedding (ModifiedOnDev  multiple                 4008      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " strand_embedding (ModifiedO  multiple                 6         \n",
      " nDeviceEmbedding)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  156800    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,486,555\n",
      "Trainable params: 7,486,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_utils.get_model(params)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "\n",
    "row_size = data_providers.get_total_rows(params.max_passes)\n",
    "input_shape = (1, row_size, params.max_length, params.num_channels)\n",
    "model_utils.print_model_summary(model, input_shape)\n",
    "checkpoint.restore(\n",
    "    checkpoint_path).expect_partial().assert_existing_objects_matched()\n",
    "\n",
    "model_utils.modify_params(\n",
    "  params=params,\n",
    "  speedy=True,\n",
    "  max_length=100,\n",
    "  is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf01ae7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_only_learned_values_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " relative_position_embedding  (100, 280)               0         \n",
      "  (RelativePositionEmbedding                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_stack (EncoderStack  {'self_attention_layer_0  7320200  \n",
      " )                           ': (None, 100, 280),                \n",
      "                              'attention_scores_0': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_0': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_1            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_1': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_1': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_2            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_2': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_2': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_3            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_3': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_3': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_4            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_4': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_4': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'final_output': (None,             \n",
      "                             100, 280)}                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100, 5)            1405      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 100, 5)            0         \n",
      "                                                                 \n",
      " bases_embedding (ModifiedOn  (None, 100, 8)           40        \n",
      " DeviceEmbedding)                                                \n",
      "                                                                 \n",
      " pw_embedding (ModifiedOnDev  (None, 100, 8)           2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " ip_embedding (ModifiedOnDev  (None, 100, 8)           2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " sn_embedding (ModifiedOnDev  (None, 100, 8)           4008      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " strand_embedding (ModifiedO  (None, 100, 2)           6         \n",
      " nDeviceEmbedding)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100, 280)          156800    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,486,555\n",
      "Trainable params: 7,486,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "inputs = Input(shape=input_shape[1:])\n",
    "outputs = model.call(inputs, training=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ea05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_output = model.predict(batch['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0d931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_preds = np.argmax(softmax_output, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0509c68",
   "metadata": {},
   "source": [
    "## Export the model in the ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4c1980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, pre_post_processing_wrapper_layer_call_fn, pre_post_processing_wrapper_layer_call_and_return_conditional_losses, pre_post_processing_wrapper_1_layer_call_fn while saving (showing 5 of 122). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deepconsensus_model/SavedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deepconsensus_model/SavedModel/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'deepconsensus_model/SavedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87fe5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 15:35:37.742235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 15:35:38.701045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 15:35:38.701127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-19 15:35:38.701138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/lslim/anaconda3/envs/mamba/envs/pbdc/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2023-01-19 15:35:39,855 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-01-19 15:35:43,523 - INFO - Signatures found in model: [serving_default].\n",
      "2023-01-19 15:35:43,524 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-01-19 15:35:43,524 - INFO - Output names: ['output_1']\n",
      "2023-01-19 15:35:48,022 - INFO - Using tensorflow=2.11.0, onnx=1.12.0, tf2onnx=1.13.0/2c1db5\n",
      "2023-01-19 15:35:48,022 - INFO - Using opset <onnx, 13>\n",
      "2023-01-19 15:35:48,812 - INFO - Computed 0 values for constant folding\n",
      "2023-01-19 15:35:50,508 - INFO - Optimizing ONNX model\n",
      "2023-01-19 15:35:54,267 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1701'.\n",
      "2023-01-19 15:35:54,702 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1749'.\n",
      "2023-01-19 15:35:54,709 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1784'.\n",
      "2023-01-19 15:35:55,076 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__1830'.\n",
      "2023-01-19 15:35:55,086 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__1876'.\n",
      "2023-01-19 15:35:55,095 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__1922'.\n",
      "2023-01-19 15:35:55,105 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__1966'.\n",
      "2023-01-19 15:35:55,112 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2001'.\n",
      "2023-01-19 15:35:55,120 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2036'.\n",
      "2023-01-19 15:35:55,129 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2071'.\n",
      "2023-01-19 15:35:55,136 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2106'.\n",
      "2023-01-19 15:35:55,145 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2141'.\n",
      "2023-01-19 15:35:55,153 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2176'.\n",
      "2023-01-19 15:35:55,163 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2224'.\n",
      "2023-01-19 15:35:55,171 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2259'.\n",
      "2023-01-19 15:35:56,052 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/output_transform/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2296'.\n",
      "2023-01-19 15:35:56,072 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2331'.\n",
      "2023-01-19 15:35:56,093 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2366'.\n",
      "2023-01-19 15:35:56,113 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2401'.\n",
      "2023-01-19 15:35:56,140 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2449'.\n",
      "2023-01-19 15:35:56,154 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__2493'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 15:35:56,162 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2528'.\n",
      "2023-01-19 15:35:56,170 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2563'.\n",
      "2023-01-19 15:35:56,179 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2598'.\n",
      "2023-01-19 15:36:03,774 - INFO - After optimization: Cast -194 (559->365), Concat +30 (110->140), Const -1239 (1523->284), Einsum -24 (30->6), Gather +60 (109->169), Gemm +16 (0->16), GlobalAveragePool +22 (0->22), Identity -13 (13->0), MatMul +8 (12->20), Max +8 (0->8), Mul -4 (229->225), Not -4 (90->86), ReduceMean -22 (22->0), ReduceProd -6 (24->18), Reshape -40 (282->242), Shape +38 (98->136), Squeeze +24 (86->110), Transpose +27 (1->28), Unsqueeze -2 (111->109)\n",
      "2023-01-19 15:36:03,902 - INFO - \n",
      "2023-01-19 15:36:03,902 - INFO - Successfully converted TensorFlow model deepconsensus_model/SavedModel/ to ONNX\n",
      "2023-01-19 15:36:03,902 - INFO - Model inputs: ['input_1']\n",
      "2023-01-19 15:36:03,902 - INFO - Model outputs: ['output_1']\n",
      "2023-01-19 15:36:03,902 - INFO - ONNX model is saved at deepconsensus_model/pbdc_temp.onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m tf2onnx.convert --saved-model deepconsensus_model/SavedModel/ --output deepconsensus_model/pbdc_temp.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c5a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load_model('deepconsensus_model/pbdc_temp.onnx')\n",
    "\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97727a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = onnx_model.graph.input\n",
    "for input in inputs:\n",
    "    dim1 = input.type.tensor_type.shape.dim[0]\n",
    "    dim1.dim_value = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ac842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepconsensus_model/pbdc.onnx\"\n",
    "onnx.save_model(onnx_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "380fd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "rm deepconsensus_model/pbdc_temp.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cf572",
   "metadata": {},
   "source": [
    "## Running the model in TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1f29269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a9f0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330f6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FP16 = False\n",
    "\n",
    "target_dtype = np.float16 if USE_FP16 else np.float32\n",
    "trt_engine = \"deepconsensus_model/pbdc_float16.trt\" if USE_FP16 else \"deepconsensus_model/pbdc_float32.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e1f242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8502] # /usr/src/tensorrt/bin/trtexec --onnx=deepconsensus_model/pbdc.onnx --saveEngine=deepconsensus_model/pbdc_float32.trt --useCudaGraph\n",
      "[01/19/2023-15:36:05] [I] === Model Options ===\n",
      "[01/19/2023-15:36:05] [I] Format: ONNX\n",
      "[01/19/2023-15:36:05] [I] Model: deepconsensus_model/pbdc.onnx\n",
      "[01/19/2023-15:36:05] [I] Output:\n",
      "[01/19/2023-15:36:05] [I] === Build Options ===\n",
      "[01/19/2023-15:36:05] [I] Max batch: explicit batch\n",
      "[01/19/2023-15:36:05] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n",
      "[01/19/2023-15:36:05] [I] minTiming: 1\n",
      "[01/19/2023-15:36:05] [I] avgTiming: 8\n",
      "[01/19/2023-15:36:05] [I] Precision: FP32\n",
      "[01/19/2023-15:36:05] [I] LayerPrecisions: \n",
      "[01/19/2023-15:36:05] [I] Calibration: \n",
      "[01/19/2023-15:36:05] [I] Refit: Disabled\n",
      "[01/19/2023-15:36:05] [I] Sparsity: Disabled\n",
      "[01/19/2023-15:36:05] [I] Safe mode: Disabled\n",
      "[01/19/2023-15:36:05] [I] DirectIO mode: Disabled\n",
      "[01/19/2023-15:36:05] [I] Restricted mode: Disabled\n",
      "[01/19/2023-15:36:05] [I] Build only: Disabled\n",
      "[01/19/2023-15:36:05] [I] Save engine: deepconsensus_model/pbdc_float32.trt\n",
      "[01/19/2023-15:36:05] [I] Load engine: \n",
      "[01/19/2023-15:36:05] [I] Profiling verbosity: 0\n",
      "[01/19/2023-15:36:05] [I] Tactic sources: Using default tactic sources\n",
      "[01/19/2023-15:36:05] [I] timingCacheMode: local\n",
      "[01/19/2023-15:36:05] [I] timingCacheFile: \n",
      "[01/19/2023-15:36:05] [I] Heuristic: Disabled\n",
      "[01/19/2023-15:36:05] [I] Preview Features: Use default preview flags.\n",
      "[01/19/2023-15:36:05] [I] Input(s)s format: fp32:CHW\n",
      "[01/19/2023-15:36:05] [I] Output(s)s format: fp32:CHW\n",
      "[01/19/2023-15:36:05] [I] Input build shapes: model\n",
      "[01/19/2023-15:36:05] [I] Input calibration shapes: model\n",
      "[01/19/2023-15:36:05] [I] === System Options ===\n",
      "[01/19/2023-15:36:05] [I] Device: 0\n",
      "[01/19/2023-15:36:05] [I] DLACore: \n",
      "[01/19/2023-15:36:05] [I] Plugins:\n",
      "[01/19/2023-15:36:05] [I] === Inference Options ===\n",
      "[01/19/2023-15:36:05] [I] Batch: Explicit\n",
      "[01/19/2023-15:36:05] [I] Input inference shapes: model\n",
      "[01/19/2023-15:36:05] [I] Iterations: 10\n",
      "[01/19/2023-15:36:05] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/19/2023-15:36:05] [I] Sleep time: 0ms\n",
      "[01/19/2023-15:36:05] [I] Idle time: 0ms\n",
      "[01/19/2023-15:36:05] [I] Streams: 1\n",
      "[01/19/2023-15:36:05] [I] ExposeDMA: Disabled\n",
      "[01/19/2023-15:36:05] [I] Data transfers: Enabled\n",
      "[01/19/2023-15:36:05] [I] Spin-wait: Disabled\n",
      "[01/19/2023-15:36:05] [I] Multithreading: Disabled\n",
      "[01/19/2023-15:36:05] [I] CUDA Graph: Enabled\n",
      "[01/19/2023-15:36:05] [I] Separate profiling: Disabled\n",
      "[01/19/2023-15:36:05] [I] Time Deserialize: Disabled\n",
      "[01/19/2023-15:36:05] [I] Time Refit: Disabled\n",
      "[01/19/2023-15:36:05] [I] NVTX verbosity: 0\n",
      "[01/19/2023-15:36:05] [I] Persistent Cache Ratio: 0\n",
      "[01/19/2023-15:36:05] [I] Inputs:\n",
      "[01/19/2023-15:36:05] [I] === Reporting Options ===\n",
      "[01/19/2023-15:36:05] [I] Verbose: Disabled\n",
      "[01/19/2023-15:36:05] [I] Averages: 10 inferences\n",
      "[01/19/2023-15:36:05] [I] Percentiles: 90,95,99\n",
      "[01/19/2023-15:36:05] [I] Dump refittable layers:Disabled\n",
      "[01/19/2023-15:36:05] [I] Dump output: Disabled\n",
      "[01/19/2023-15:36:05] [I] Profile: Disabled\n",
      "[01/19/2023-15:36:05] [I] Export timing to JSON file: \n",
      "[01/19/2023-15:36:05] [I] Export output to JSON file: \n",
      "[01/19/2023-15:36:05] [I] Export profile to JSON file: \n",
      "[01/19/2023-15:36:05] [I] \n",
      "[01/19/2023-15:36:05] [I] === Device Information ===\n",
      "[01/19/2023-15:36:05] [I] Selected Device: Tesla V100-DGXS-32GB\n",
      "[01/19/2023-15:36:05] [I] Compute Capability: 7.0\n",
      "[01/19/2023-15:36:05] [I] SMs: 80\n",
      "[01/19/2023-15:36:05] [I] Compute Clock Rate: 1.53 GHz\n",
      "[01/19/2023-15:36:05] [I] Device Global Memory: 32508 MiB\n",
      "[01/19/2023-15:36:05] [I] Shared Memory per SM: 96 KiB\n",
      "[01/19/2023-15:36:05] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[01/19/2023-15:36:05] [I] Memory Clock Rate: 0.877 GHz\n",
      "[01/19/2023-15:36:05] [I] \n",
      "[01/19/2023-15:36:05] [I] TensorRT version: 8.5.2\n",
      "[01/19/2023-15:36:05] [I] [TRT] [MemUsageChange] Init CUDA: CPU +11, GPU +0, now: CPU 23, GPU 615 (MiB)\n",
      "[01/19/2023-15:36:08] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +171, GPU +46, now: CPU 249, GPU 661 (MiB)\n",
      "[01/19/2023-15:36:08] [I] Start parsing network model\n",
      "[01/19/2023-15:36:08] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/19/2023-15:36:08] [I] [TRT] Input filename:   deepconsensus_model/pbdc.onnx\n",
      "[01/19/2023-15:36:08] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[01/19/2023-15:36:08] [I] [TRT] Opset version:    13\n",
      "[01/19/2023-15:36:08] [I] [TRT] Producer name:    tf2onnx\n",
      "[01/19/2023-15:36:08] [I] [TRT] Producer version: 1.13.0 2c1db5\n",
      "[01/19/2023-15:36:08] [I] [TRT] Domain:           \n",
      "[01/19/2023-15:36:08] [I] [TRT] Model version:    0\n",
      "[01/19/2023-15:36:08] [I] [TRT] Doc string:       \n",
      "[01/19/2023-15:36:08] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/19/2023-15:36:08] [W] [TRT] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/19/2023-15:36:13] [I] Finish parsing network model\n",
      "[01/19/2023-15:36:14] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +257, GPU +12, now: CPU 549, GPU 673 (MiB)\n",
      "[01/19/2023-15:36:14] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 551, GPU 683 (MiB)\n",
      "[01/19/2023-15:36:14] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/19/2023-15:36:45] [I] [TRT] Total Activation Memory: 34087501824\n",
      "[01/19/2023-15:36:45] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[01/19/2023-15:36:46] [I] [TRT] Total Host Persistent Memory: 32\n",
      "[01/19/2023-15:36:46] [I] [TRT] Total Device Persistent Memory: 0\n",
      "[01/19/2023-15:36:46] [I] [TRT] Total Scratch Memory: 1257472000\n",
      "[01/19/2023-15:36:46] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 1246 MiB\n",
      "[01/19/2023-15:36:46] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 1 steps to complete.\n",
      "[01/19/2023-15:36:46] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.010512ms to assign 1 blocks to 1 nodes requiring 1257472000 bytes.\n",
      "[01/19/2023-15:36:46] [I] [TRT] Total Activation Memory: 1257472000\n",
      "[01/19/2023-15:36:46] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +32, now: CPU 0, GPU 32 (MiB)\n",
      "[01/19/2023-15:36:46] [I] Engine built in 41.0083 sec.\n",
      "[01/19/2023-15:36:46] [I] [TRT] Loaded engine size: 29 MiB\n",
      "[01/19/2023-15:36:46] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +28, now: CPU 0, GPU 28 (MiB)\n",
      "[01/19/2023-15:36:46] [I] Engine deserialized in 0.0132955 sec.\n",
      "[01/19/2023-15:36:46] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1199, now: CPU 0, GPU 1227 (MiB)\n",
      "[01/19/2023-15:36:46] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/19/2023-15:36:46] [I] Using random values for input input_1\n",
      "[01/19/2023-15:36:46] [I] Created input binding for input_1 with dimensions 512x85x100x1\n",
      "[01/19/2023-15:36:46] [I] Using random values for output output_1\n",
      "[01/19/2023-15:36:46] [I] Created output binding for output_1 with dimensions 512x100x5\n",
      "[01/19/2023-15:36:46] [I] Starting inference\n",
      "[01/19/2023-15:36:50] [I] Warmup completed 2 queries over 200 ms\n",
      "[01/19/2023-15:36:50] [I] Timing trace has 42 queries over 3.23288 s\n",
      "[01/19/2023-15:36:50] [I] \n",
      "[01/19/2023-15:36:50] [I] === Trace details ===\n",
      "[01/19/2023-15:36:50] [I] Trace averages of 10 runs:\n",
      "[01/19/2023-15:36:50] [I] Average on 10 runs - GPU latency: 75.3529 ms - Host latency: 76.9452 ms (enqueue 0.0678085 ms)\n",
      "[01/19/2023-15:36:50] [I] Average on 10 runs - GPU latency: 75.1674 ms - Host latency: 76.8229 ms (enqueue 0.0995178 ms)\n",
      "[01/19/2023-15:36:50] [I] Average on 10 runs - GPU latency: 75.1217 ms - Host latency: 76.7667 ms (enqueue 0.0854126 ms)\n",
      "[01/19/2023-15:36:50] [I] Average on 10 runs - GPU latency: 75.4088 ms - Host latency: 77.0417 ms (enqueue 0.0881348 ms)\n",
      "[01/19/2023-15:36:50] [I] \n",
      "[01/19/2023-15:36:50] [I] === Performance summary ===\n",
      "[01/19/2023-15:36:50] [I] Throughput: 12.9915 qps\n",
      "[01/19/2023-15:36:50] [I] Latency: min = 76.3232 ms, max = 77.3225 ms, mean = 76.8926 ms, median = 76.8847 ms, percentile(90%) = 77.2589 ms, percentile(95%) = 77.2738 ms, percentile(99%) = 77.3225 ms\n",
      "[01/19/2023-15:36:50] [I] Enqueue Time: min = 0.0507202 ms, max = 0.134521 ms, mean = 0.0858688 ms, median = 0.0872192 ms, percentile(90%) = 0.100098 ms, percentile(95%) = 0.101196 ms, percentile(99%) = 0.134521 ms\n",
      "[01/19/2023-15:36:50] [I] H2D Latency: min = 1.41316 ms, max = 1.57227 ms, mean = 1.5334 ms, median = 1.54907 ms, percentile(90%) = 1.56323 ms, percentile(95%) = 1.56409 ms, percentile(99%) = 1.57227 ms\n",
      "[01/19/2023-15:36:50] [I] GPU Compute Time: min = 74.704 ms, max = 75.817 ms, mean = 75.2605 ms, median = 75.2424 ms, percentile(90%) = 75.649 ms, percentile(95%) = 75.6838 ms, percentile(99%) = 75.817 ms\n",
      "[01/19/2023-15:36:50] [I] D2H Latency: min = 0.0834961 ms, max = 0.112732 ms, mean = 0.0987767 ms, median = 0.0960693 ms, percentile(90%) = 0.108765 ms, percentile(95%) = 0.111206 ms, percentile(99%) = 0.112732 ms\n",
      "[01/19/2023-15:36:50] [I] Total Host Walltime: 3.23288 s\n",
      "[01/19/2023-15:36:50] [I] Total GPU Compute Time: 3.16094 s\n",
      "[01/19/2023-15:36:50] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/19/2023-15:36:50] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8502] # /usr/src/tensorrt/bin/trtexec --onnx=deepconsensus_model/pbdc.onnx --saveEngine=deepconsensus_model/pbdc_float32.trt --useCudaGraph\n"
     ]
    }
   ],
   "source": [
    "if USE_FP16:\n",
    "    !/usr/src/tensorrt/bin/trtexec --onnx=\"deepconsensus_model/pbdc.onnx\" --saveEngine=\"$trt_engine\" --useCudaGraph --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n",
    "else:\n",
    "    !/usr/src/tensorrt/bin/trtexec --onnx=\"deepconsensus_model/pbdc.onnx\" --saveEngine=\"$trt_engine\" --useCudaGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dcc8e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/19/2023-15:36:50] [TRT] [W]  (foreignNode) cuBLASLt subversions: compiled against 11.10.3.0 but running against 11.11.3.0.\n"
     ]
    }
   ],
   "source": [
    "f = open(trt_engine, \"rb\")\n",
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING)) \n",
    "\n",
    "engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b35301",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = np.empty(softmax_output.numpy().shape, dtype = target_dtype)\n",
    "\n",
    "# Allocate device memory\n",
    "d_input = cuda.mem_alloc(1 * batch['rows'].numpy().nbytes)\n",
    "d_output = cuda.mem_alloc(1 * batch_output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16cbc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpredict(batch): # result gets copied into output\n",
    "    # Transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # Execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)\n",
    "    # Transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(batch_output, d_output, stream)\n",
    "    # Syncronize threads\n",
    "    stream.synchronize()\n",
    "    \n",
    "    return batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2725c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_softmax_output = tpredict(batch['rows']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cba34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_preds = np.argmax(trt_softmax_output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa16965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differnce between TF and TRT predictions measured by L2 norm: 0.00002537\n"
     ]
    }
   ],
   "source": [
    "l2_diff = np.linalg.norm(trt_softmax_output - softmax_output)\n",
    "print(\"Differnce between TF and TRT predictions measured by L2 norm: {:.8f}\".format(l2_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82ab909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "batch_accuracy = np.isclose(batch['label'].numpy(), trt_preds).mean()\n",
    "print(\"Batch accuracy: {:.3f}\".format(batch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641cbb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset average accuracy: 0.778\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for i, batch in enumerate(ds.take(count=-1)):\n",
    "    trt_softmax_output = tpredict(batch['rows']).astype(np.float32)\n",
    "    trt_preds = np.argmax(trt_softmax_output, -1)\n",
    "    acc = (acc * i + np.isclose(batch['label'].numpy(), trt_preds).mean()) / (i + 1)\n",
    "    \n",
    "print(\"Dataset average accuracy: {:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6f53b",
   "metadata": {},
   "source": [
    "## Assessing DeepConsensus accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94bacf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/train/tf-train-00000-of-00500.tfrecord.gz...\n",
      "| [1 files][  2.2 GiB/  2.2 GiB]   62.4 MiB/s                                   \n",
      "Operation completed over 1 objects/2.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p train\n",
    "\n",
    "gsutil cp gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/train/tf-train-00000-of-00500.tfrecord.gz ./train/tf-train-00000-of-00500.tfrecord.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5b72711",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"train/tf-train-00000-of-00500.tfrecord.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6ea5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_providers.get_dataset(dataset_path,\n",
    "                                num_epochs=None,\n",
    "                                batch_size=batch_size,\n",
    "                                params=params,\n",
    "                                inference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8198dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 15:47:41.674220: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 80426 of 1000000\n",
      "2023-01-19 15:47:51.674541: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 162066 of 1000000\n",
      "2023-01-19 15:48:01.674256: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 242730 of 1000000\n",
      "2023-01-19 15:48:11.674441: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 324285 of 1000000\n",
      "2023-01-19 15:48:21.674368: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 404690 of 1000000\n",
      "2023-01-19 15:48:31.674582: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 486079 of 1000000\n",
      "2023-01-19 15:48:41.674264: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 567717 of 1000000\n",
      "2023-01-19 15:48:51.674168: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 649511 of 1000000\n",
      "2023-01-19 15:49:01.674693: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 730075 of 1000000\n",
      "2023-01-19 15:49:11.674307: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 810619 of 1000000\n",
      "2023-01-19 15:49:12.570648: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset average accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for i, batch in enumerate(ds.take(count=-1)):\n",
    "    trt_softmax_output = tpredict(batch['rows']).astype(np.float32)\n",
    "    trt_preds = np.argmax(trt_softmax_output, -1)\n",
    "    acc = (acc * i + np.isclose(batch['label'].numpy(), trt_preds).mean()) / (i + 1)\n",
    "    \n",
    "print(\"Dataset average accuracy: {:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cb7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
