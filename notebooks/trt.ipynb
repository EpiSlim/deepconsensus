{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30971cc",
   "metadata": {},
   "source": [
    "# Running DeepConsensus in TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef224e9b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b37c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash \n",
    "\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# pip install deepconsensus[gpu]==1.1.0 onnxruntime tensorrt pycuda tf2onnx gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ddf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fdf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f194b3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 22:53:02.161060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 22:53:03.149763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 22:53:03.149853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 22:53:03.149865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "import colorama\n",
    "import numpy as np\n",
    "import random\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "from deepconsensus.models import model_configs\n",
    "from deepconsensus.models import model_utils\n",
    "from deepconsensus.models import data_providers\n",
    "from deepconsensus.utils import dc_constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcb273",
   "metadata": {},
   "source": [
    "## Load the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276b3cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/checkpoint.data-00000-of-00001...\n",
      "Copying gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/checkpoint.index...\n",
      "Copying gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/params.json...\n",
      "| [3 files][ 85.7 MiB/ 85.7 MiB]                                                \n",
      "Operation completed over 3 objects/85.7 MiB.                                     \n",
      "Copying gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/test/tf-test-00000-of-00500.tfrecord.gz...\n",
      "| [1 files][ 90.6 MiB/ 90.6 MiB]                                                \n",
      "Operation completed over 1 objects/90.6 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Download Model\n",
    "mkdir -p deepconsensus_model\n",
    "gsutil cp -r gs://brain-genomics-public/research/deepconsensus/models/v1.1/model_checkpoint/* deepconsensus_model/\n",
    "# Download test data\n",
    "gsutil cp gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/test/tf-test-00000-of-00500.tfrecord.gz ./tf-test.tfrecord.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37dd22e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 22:53:10.496734: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-25 22:53:10.496775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: hcsa-dgx32gb\n",
      "2023-01-25 22:53:10.496785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: hcsa-dgx32gb\n",
      "2023-01-25 22:53:10.496886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.1\n",
      "2023-01-25 22:53:10.496922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n",
      "2023-01-25 22:53:10.496930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.65.1\n",
      "2023-01-25 22:53:10.497373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name.shape: (8192, 1)\n",
      "label.shape: (8192, 100)\n",
      "rows.shape: (8192, 85, 100, 1)\n",
      "num_passes.shape: (8192, 1)\n",
      "window_pos.shape: (8192, 1)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'deepconsensus_model/checkpoint'\n",
    "params = model_utils.read_params_from_json(checkpoint_path=checkpoint_path)\n",
    "\n",
    "tfrecord_path = 'tf-test.tfrecord.gz'\n",
    "\n",
    "# Number of examples:\n",
    "batch_size = 8192  #@param\n",
    "\n",
    "ds = data_providers.get_dataset(tfrecord_path,\n",
    "                                num_epochs=None,\n",
    "                                batch_size=batch_size,\n",
    "                                params=params,\n",
    "                                inference=False)\n",
    "\n",
    "# Just get one batch to inspect:\n",
    "for batch in ds.take(1):\n",
    "  break\n",
    "\n",
    "keys = ['name', 'label', 'rows', 'num_passes', 'window_pos']\n",
    "for key in keys:\n",
    "  print(f'{key}.shape: {batch[key].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975e7e7",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7debf0c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_only_learned_values_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " relative_position_embedding  multiple                 0         \n",
      "  (RelativePositionEmbedding                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_stack (EncoderStack  multiple                 7320200   \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  1405      \n",
      "                                                                 \n",
      " softmax (Softmax)           multiple                  0         \n",
      "                                                                 \n",
      " bases_embedding (ModifiedOn  multiple                 40        \n",
      " DeviceEmbedding)                                                \n",
      "                                                                 \n",
      " pw_embedding (ModifiedOnDev  multiple                 2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " ip_embedding (ModifiedOnDev  multiple                 2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " sn_embedding (ModifiedOnDev  multiple                 4008      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " strand_embedding (ModifiedO  multiple                 6         \n",
      " nDeviceEmbedding)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  156800    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,486,555\n",
      "Trainable params: 7,486,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_utils.get_model(params)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "\n",
    "row_size = data_providers.get_total_rows(params.max_passes)\n",
    "input_shape = (1, row_size, params.max_length, params.num_channels)\n",
    "model_utils.print_model_summary(model, input_shape)\n",
    "checkpoint.restore(\n",
    "    checkpoint_path).expect_partial().assert_existing_objects_matched()\n",
    "\n",
    "model_utils.modify_params(\n",
    "  params=params,\n",
    "  speedy=True,\n",
    "  max_length=100,\n",
    "  is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf01ae7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_only_learned_values_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " relative_position_embedding  (100, 280)               0         \n",
      "  (RelativePositionEmbedding                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " encoder_stack (EncoderStack  {'self_attention_layer_0  7320200  \n",
      " )                           ': (None, 100, 280),                \n",
      "                              'attention_scores_0': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_0': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_1            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_1': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_1': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_2            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_2': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_2': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_3            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_3': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_3': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'self_attention_layer_4            \n",
      "                             ': (None, 100, 280),                \n",
      "                              'attention_scores_4': (            \n",
      "                             None, 2, 100, 100),                 \n",
      "                              'ffn_layer_4': (None, 1            \n",
      "                             00, 280),                           \n",
      "                              'final_output': (None,             \n",
      "                             100, 280)}                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100, 5)            1405      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 100, 5)            0         \n",
      "                                                                 \n",
      " bases_embedding (ModifiedOn  (None, 100, 8)           40        \n",
      " DeviceEmbedding)                                                \n",
      "                                                                 \n",
      " pw_embedding (ModifiedOnDev  (None, 100, 8)           2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " ip_embedding (ModifiedOnDev  (None, 100, 8)           2048      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " sn_embedding (ModifiedOnDev  (None, 100, 8)           4008      \n",
      " iceEmbedding)                                                   \n",
      "                                                                 \n",
      " strand_embedding (ModifiedO  (None, 100, 2)           6         \n",
      " nDeviceEmbedding)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100, 280)          156800    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,486,555\n",
      "Trainable params: 7,486,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "inputs = Input(shape=input_shape[1:])\n",
    "outputs = model.call(inputs, training=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75ea05a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_output = model.predict(batch['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0d931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_preds = np.argmax(softmax_output, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0509c68",
   "metadata": {},
   "source": [
    "## Export the model in the ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4c1980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, pre_post_processing_wrapper_layer_call_fn, pre_post_processing_wrapper_layer_call_and_return_conditional_losses, pre_post_processing_wrapper_1_layer_call_fn while saving (showing 5 of 122). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deepconsensus_model/SavedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deepconsensus_model/SavedModel/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'deepconsensus_model/SavedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87fe5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 22:54:20.380121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 22:54:21.345931: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 22:54:21.346010: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-25 22:54:21.346021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/lslim/anaconda3/envs/mamba/envs/pbdc/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2023-01-25 22:54:22,504 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-01-25 22:54:26,395 - INFO - Signatures found in model: [serving_default].\n",
      "2023-01-25 22:54:26,395 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-01-25 22:54:26,396 - INFO - Output names: ['output_1']\n",
      "2023-01-25 22:54:31,044 - INFO - Using tensorflow=2.11.0, onnx=1.12.0, tf2onnx=1.13.0/2c1db5\n",
      "2023-01-25 22:54:31,044 - INFO - Using opset <onnx, 13>\n",
      "2023-01-25 22:54:31,933 - INFO - Computed 0 values for constant folding\n",
      "2023-01-25 22:54:33,766 - INFO - Optimizing ONNX model\n",
      "2023-01-25 22:54:37,671 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1701'.\n",
      "2023-01-25 22:54:38,586 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/output_transform/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1738'.\n",
      "2023-01-25 22:54:38,608 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1773'.\n",
      "2023-01-25 22:54:39,029 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1821'.\n",
      "2023-01-25 22:54:39,398 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__1867'.\n",
      "2023-01-25 22:54:39,406 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1902'.\n",
      "2023-01-25 22:54:39,417 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/einsum/Einsum' by its decomposed version, name of the last node 'Identity__1950'.\n",
      "2023-01-25 22:54:39,427 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__1996'.\n",
      "2023-01-25 22:54:39,435 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2031'.\n",
      "2023-01-25 22:54:39,444 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2066'.\n",
      "2023-01-25 22:54:39,453 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2101'.\n",
      "2023-01-25 22:54:39,461 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_1/self_attention/pre_post_processing_wrapper_2/self_attention_1/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2136'.\n",
      "2023-01-25 22:54:39,470 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/output_transform/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2173'.\n",
      "2023-01-25 22:54:39,479 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/output_transform/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2210'.\n",
      "2023-01-25 22:54:39,487 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2245'.\n",
      "2023-01-25 22:54:39,495 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2280'.\n",
      "2023-01-25 22:54:39,506 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__2326'.\n",
      "2023-01-25 22:54:39,514 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2361'.\n",
      "2023-01-25 22:54:39,524 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__2407'.\n",
      "2023-01-25 22:54:39,532 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/key/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2442'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 22:54:39,541 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2477'.\n",
      "2023-01-25 22:54:39,549 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_3/self_attention/pre_post_processing_wrapper_6/self_attention_3/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2512'.\n",
      "2023-01-25 22:54:39,557 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_2/self_attention/pre_post_processing_wrapper_4/self_attention_2/query/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2547'.\n",
      "2023-01-25 22:54:39,568 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_4/self_attention/pre_post_processing_wrapper_8/self_attention_4/einsum_1/Einsum' by its decomposed version, name of the last node 'Identity__2591'.\n",
      "2023-01-25 22:54:39,576 - INFO - replacing einsum node 'StatefulPartitionedCall/encoder_only_learned_values_transformer/Transformer/encode/encoder_stack/layer_0/self_attention/pre_post_processing_wrapper/self_attention/value/einsum/Einsum' by its decomposed version, name of the last node 'Identity__2626'.\n",
      "2023-01-25 22:54:47,536 - INFO - After optimization: Cast -194 (559->365), Concat +33 (110->143), Const -1239 (1523->284), Einsum -25 (30->5), Gather +62 (109->171), Gemm +18 (0->18), GlobalAveragePool +22 (0->22), Identity -13 (13->0), MatMul +7 (12->19), Max +7 (0->7), Mul -4 (229->225), Not -4 (90->86), ReduceMean -22 (22->0), ReduceProd -4 (24->20), Reshape -37 (282->245), Shape +40 (98->138), Squeeze +25 (86->111), Transpose +23 (1->24), Unsqueeze -2 (111->109)\n",
      "2023-01-25 22:54:47,670 - INFO - \n",
      "2023-01-25 22:54:47,670 - INFO - Successfully converted TensorFlow model deepconsensus_model/SavedModel/ to ONNX\n",
      "2023-01-25 22:54:47,670 - INFO - Model inputs: ['input_1']\n",
      "2023-01-25 22:54:47,670 - INFO - Model outputs: ['output_1']\n",
      "2023-01-25 22:54:47,670 - INFO - ONNX model is saved at deepconsensus_model/pbdc_temp.onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m tf2onnx.convert --saved-model deepconsensus_model/SavedModel/ --output deepconsensus_model/pbdc_temp.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c5a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load_model('deepconsensus_model/pbdc_temp.onnx')\n",
    "\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97727a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = onnx_model.graph.input\n",
    "for input in inputs:\n",
    "    dim1 = input.type.tensor_type.shape.dim[0]\n",
    "    dim1.dim_value = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ac842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepconsensus_model/pbdc.onnx\"\n",
    "onnx.save_model(onnx_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "380fd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "rm deepconsensus_model/pbdc_temp.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cf572",
   "metadata": {},
   "source": [
    "## Running the model in TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfa4c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "igpu = 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(igpu)\n",
    "os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a9f0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330f6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FP16 = False\n",
    "\n",
    "target_dtype = np.float16 if USE_FP16 else np.float32\n",
    "trt_engine = \"deepconsensus_model/pbdc_float16.trt\" if USE_FP16 else \"deepconsensus_model/pbdc_float32.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e1f242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8502] # /usr/src/tensorrt/bin/trtexec --onnx=deepconsensus_model/pbdc.onnx --saveEngine=deepconsensus_model/pbdc_float32.trt --useCudaGraph\n",
      "[01/25/2023-22:54:49] [I] === Model Options ===\n",
      "[01/25/2023-22:54:49] [I] Format: ONNX\n",
      "[01/25/2023-22:54:49] [I] Model: deepconsensus_model/pbdc.onnx\n",
      "[01/25/2023-22:54:49] [I] Output:\n",
      "[01/25/2023-22:54:49] [I] === Build Options ===\n",
      "[01/25/2023-22:54:49] [I] Max batch: explicit batch\n",
      "[01/25/2023-22:54:49] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n",
      "[01/25/2023-22:54:49] [I] minTiming: 1\n",
      "[01/25/2023-22:54:49] [I] avgTiming: 8\n",
      "[01/25/2023-22:54:49] [I] Precision: FP32\n",
      "[01/25/2023-22:54:49] [I] LayerPrecisions: \n",
      "[01/25/2023-22:54:49] [I] Calibration: \n",
      "[01/25/2023-22:54:49] [I] Refit: Disabled\n",
      "[01/25/2023-22:54:49] [I] Sparsity: Disabled\n",
      "[01/25/2023-22:54:49] [I] Safe mode: Disabled\n",
      "[01/25/2023-22:54:49] [I] DirectIO mode: Disabled\n",
      "[01/25/2023-22:54:49] [I] Restricted mode: Disabled\n",
      "[01/25/2023-22:54:49] [I] Build only: Disabled\n",
      "[01/25/2023-22:54:49] [I] Save engine: deepconsensus_model/pbdc_float32.trt\n",
      "[01/25/2023-22:54:49] [I] Load engine: \n",
      "[01/25/2023-22:54:49] [I] Profiling verbosity: 0\n",
      "[01/25/2023-22:54:49] [I] Tactic sources: Using default tactic sources\n",
      "[01/25/2023-22:54:49] [I] timingCacheMode: local\n",
      "[01/25/2023-22:54:49] [I] timingCacheFile: \n",
      "[01/25/2023-22:54:49] [I] Heuristic: Disabled\n",
      "[01/25/2023-22:54:49] [I] Preview Features: Use default preview flags.\n",
      "[01/25/2023-22:54:49] [I] Input(s)s format: fp32:CHW\n",
      "[01/25/2023-22:54:49] [I] Output(s)s format: fp32:CHW\n",
      "[01/25/2023-22:54:49] [I] Input build shapes: model\n",
      "[01/25/2023-22:54:49] [I] Input calibration shapes: model\n",
      "[01/25/2023-22:54:49] [I] === System Options ===\n",
      "[01/25/2023-22:54:49] [I] Device: 0\n",
      "[01/25/2023-22:54:49] [I] DLACore: \n",
      "[01/25/2023-22:54:49] [I] Plugins:\n",
      "[01/25/2023-22:54:49] [I] === Inference Options ===\n",
      "[01/25/2023-22:54:49] [I] Batch: Explicit\n",
      "[01/25/2023-22:54:49] [I] Input inference shapes: model\n",
      "[01/25/2023-22:54:49] [I] Iterations: 10\n",
      "[01/25/2023-22:54:49] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/25/2023-22:54:49] [I] Sleep time: 0ms\n",
      "[01/25/2023-22:54:49] [I] Idle time: 0ms\n",
      "[01/25/2023-22:54:49] [I] Streams: 1\n",
      "[01/25/2023-22:54:49] [I] ExposeDMA: Disabled\n",
      "[01/25/2023-22:54:49] [I] Data transfers: Enabled\n",
      "[01/25/2023-22:54:49] [I] Spin-wait: Disabled\n",
      "[01/25/2023-22:54:49] [I] Multithreading: Disabled\n",
      "[01/25/2023-22:54:49] [I] CUDA Graph: Enabled\n",
      "[01/25/2023-22:54:49] [I] Separate profiling: Disabled\n",
      "[01/25/2023-22:54:49] [I] Time Deserialize: Disabled\n",
      "[01/25/2023-22:54:49] [I] Time Refit: Disabled\n",
      "[01/25/2023-22:54:49] [I] NVTX verbosity: 0\n",
      "[01/25/2023-22:54:49] [I] Persistent Cache Ratio: 0\n",
      "[01/25/2023-22:54:49] [I] Inputs:\n",
      "[01/25/2023-22:54:49] [I] === Reporting Options ===\n",
      "[01/25/2023-22:54:49] [I] Verbose: Disabled\n",
      "[01/25/2023-22:54:49] [I] Averages: 10 inferences\n",
      "[01/25/2023-22:54:49] [I] Percentiles: 90,95,99\n",
      "[01/25/2023-22:54:49] [I] Dump refittable layers:Disabled\n",
      "[01/25/2023-22:54:49] [I] Dump output: Disabled\n",
      "[01/25/2023-22:54:49] [I] Profile: Disabled\n",
      "[01/25/2023-22:54:49] [I] Export timing to JSON file: \n",
      "[01/25/2023-22:54:49] [I] Export output to JSON file: \n",
      "[01/25/2023-22:54:49] [I] Export profile to JSON file: \n",
      "[01/25/2023-22:54:49] [I] \n",
      "[01/25/2023-22:54:49] [I] === Device Information ===\n",
      "[01/25/2023-22:54:49] [I] Selected Device: Tesla V100-DGXS-32GB\n",
      "[01/25/2023-22:54:49] [I] Compute Capability: 7.0\n",
      "[01/25/2023-22:54:49] [I] SMs: 80\n",
      "[01/25/2023-22:54:49] [I] Compute Clock Rate: 1.53 GHz\n",
      "[01/25/2023-22:54:49] [I] Device Global Memory: 32508 MiB\n",
      "[01/25/2023-22:54:49] [I] Shared Memory per SM: 96 KiB\n",
      "[01/25/2023-22:54:49] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[01/25/2023-22:54:49] [I] Memory Clock Rate: 0.877 GHz\n",
      "[01/25/2023-22:54:49] [I] \n",
      "[01/25/2023-22:54:49] [I] TensorRT version: 8.5.2\n",
      "[01/25/2023-22:54:49] [I] [TRT] [MemUsageChange] Init CUDA: CPU +11, GPU +0, now: CPU 23, GPU 615 (MiB)\n",
      "[01/25/2023-22:54:52] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +171, GPU +46, now: CPU 249, GPU 661 (MiB)\n",
      "[01/25/2023-22:54:52] [I] Start parsing network model\n",
      "[01/25/2023-22:54:52] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/25/2023-22:54:52] [I] [TRT] Input filename:   deepconsensus_model/pbdc.onnx\n",
      "[01/25/2023-22:54:52] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[01/25/2023-22:54:52] [I] [TRT] Opset version:    13\n",
      "[01/25/2023-22:54:52] [I] [TRT] Producer name:    tf2onnx\n",
      "[01/25/2023-22:54:52] [I] [TRT] Producer version: 1.13.0 2c1db5\n",
      "[01/25/2023-22:54:52] [I] [TRT] Domain:           \n",
      "[01/25/2023-22:54:52] [I] [TRT] Model version:    0\n",
      "[01/25/2023-22:54:52] [I] [TRT] Doc string:       \n",
      "[01/25/2023-22:54:52] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/25/2023-22:54:52] [W] [TRT] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[01/25/2023-22:54:57] [I] Finish parsing network model\n",
      "[01/25/2023-22:54:58] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +257, GPU +12, now: CPU 549, GPU 673 (MiB)\n",
      "[01/25/2023-22:54:58] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 551, GPU 683 (MiB)\n",
      "[01/25/2023-22:54:58] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/25/2023-22:59:43] [I] [TRT] Total Activation Memory: 34087501824\n",
      "[01/25/2023-22:59:43] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[01/25/2023-22:59:44] [I] [TRT] Total Host Persistent Memory: 32\n",
      "[01/25/2023-22:59:44] [I] [TRT] Total Device Persistent Memory: 0\n",
      "[01/25/2023-22:59:44] [I] [TRT] Total Scratch Memory: 20119552000\n",
      "[01/25/2023-22:59:44] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 19498 MiB\n",
      "[01/25/2023-22:59:44] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 1 steps to complete.\n",
      "[01/25/2023-22:59:44] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.011255ms to assign 1 blocks to 1 nodes requiring 20119552000 bytes.\n",
      "[01/25/2023-22:59:44] [I] [TRT] Total Activation Memory: 20119552000\n",
      "[01/25/2023-22:59:44] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +32, now: CPU 0, GPU 32 (MiB)\n",
      "[01/25/2023-22:59:44] [I] Engine built in 294.907 sec.\n",
      "[01/25/2023-22:59:44] [I] [TRT] Loaded engine size: 29 MiB\n",
      "[01/25/2023-22:59:44] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +28, now: CPU 0, GPU 28 (MiB)\n",
      "[01/25/2023-22:59:44] [I] Engine deserialized in 0.0164625 sec.\n",
      "[01/25/2023-22:59:44] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +19188, now: CPU 0, GPU 19216 (MiB)\n",
      "[01/25/2023-22:59:44] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/25/2023-22:59:44] [I] Using random values for input input_1\n",
      "[01/25/2023-22:59:44] [I] Created input binding for input_1 with dimensions 8192x85x100x1\n",
      "[01/25/2023-22:59:44] [I] Using random values for output output_1\n",
      "[01/25/2023-22:59:44] [I] Created output binding for output_1 with dimensions 8192x100x5\n",
      "[01/25/2023-22:59:44] [I] Starting inference\n",
      "[01/25/2023-22:59:58] [I] Warmup completed 0 queries over 200 ms\n",
      "[01/25/2023-22:59:58] [I] Timing trace has 10 queries over 12.3366 s\n",
      "[01/25/2023-22:59:58] [I] \n",
      "[01/25/2023-22:59:58] [I] === Trace details ===\n",
      "[01/25/2023-22:59:58] [I] Trace averages of 10 runs:\n",
      "[01/25/2023-22:59:58] [I] Average on 10 runs - GPU latency: 1230.94 ms - Host latency: 1257.03 ms (enqueue 0.0819946 ms)\n",
      "[01/25/2023-22:59:58] [I] \n",
      "[01/25/2023-22:59:58] [I] === Performance summary ===\n",
      "[01/25/2023-22:59:58] [I] Throughput: 0.810593 qps\n",
      "[01/25/2023-22:59:58] [I] Latency: min = 1251.62 ms, max = 1261.43 ms, mean = 1257.03 ms, median = 1257.03 ms, percentile(90%) = 1259.76 ms, percentile(95%) = 1261.43 ms, percentile(99%) = 1261.43 ms\n",
      "[01/25/2023-22:59:58] [I] Enqueue Time: min = 0.0429688 ms, max = 0.122803 ms, mean = 0.0819946 ms, median = 0.0849609 ms, percentile(90%) = 0.0991211 ms, percentile(95%) = 0.122803 ms, percentile(99%) = 0.122803 ms\n",
      "[01/25/2023-22:59:58] [I] H2D Latency: min = 24.0645 ms, max = 27.0627 ms, mean = 24.6042 ms, median = 24.1431 ms, percentile(90%) = 25.9392 ms, percentile(95%) = 27.0627 ms, percentile(99%) = 27.0627 ms\n",
      "[01/25/2023-22:59:58] [I] GPU Compute Time: min = 1225.93 ms, max = 1235.78 ms, mean = 1230.94 ms, median = 1230.83 ms, percentile(90%) = 1234.14 ms, percentile(95%) = 1235.78 ms, percentile(99%) = 1235.78 ms\n",
      "[01/25/2023-22:59:58] [I] D2H Latency: min = 1.25 ms, max = 1.54102 ms, mean = 1.48247 ms, median = 1.50586 ms, percentile(90%) = 1.5249 ms, percentile(95%) = 1.54102 ms, percentile(99%) = 1.54102 ms\n",
      "[01/25/2023-22:59:58] [I] Total Host Walltime: 12.3366 s\n",
      "[01/25/2023-22:59:58] [I] Total GPU Compute Time: 12.3094 s\n",
      "[01/25/2023-22:59:58] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/25/2023-22:59:58] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8502] # /usr/src/tensorrt/bin/trtexec --onnx=deepconsensus_model/pbdc.onnx --saveEngine=deepconsensus_model/pbdc_float32.trt --useCudaGraph\n"
     ]
    }
   ],
   "source": [
    "if USE_FP16:\n",
    "    !/usr/src/tensorrt/bin/trtexec --onnx=\"deepconsensus_model/pbdc.onnx\" --saveEngine=\"$trt_engine\" --useCudaGraph --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n",
    "else:\n",
    "    !/usr/src/tensorrt/bin/trtexec --onnx=\"deepconsensus_model/pbdc.onnx\" --saveEngine=\"$trt_engine\" --useCudaGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dcc8e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/25/2023-22:59:59] [TRT] [W]  (foreignNode) cuBLASLt subversions: compiled against 11.10.3.0 but running against 11.11.3.0.\n"
     ]
    }
   ],
   "source": [
    "f = open(trt_engine, \"rb\")\n",
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING)) \n",
    "\n",
    "engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b35301",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = np.empty(softmax_output.numpy().shape, dtype = target_dtype)\n",
    "\n",
    "# Allocate device memory\n",
    "d_input = cuda.mem_alloc(1 * batch['rows'].numpy().nbytes)\n",
    "d_output = cuda.mem_alloc(1 * batch_output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16cbc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda import driver\n",
    "\n",
    "def tpredict(batch): # result gets copied into output\n",
    "    # Transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # Execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)\n",
    "    # Transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(batch_output, d_output, stream)\n",
    "    # Syncronize threads\n",
    "    stream.synchronize()\n",
    "    \n",
    "    return batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2725c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_softmax_output = tpredict(batch['rows']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cba34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_preds = np.argmax(trt_softmax_output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ce05910",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_utils.get_deepconsensus_loss(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82ab909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 0.538\n"
     ]
    }
   ],
   "source": [
    "batch_loss = loss.eval(batch['label'], trt_softmax_output).numpy().mean()\n",
    "print(\"Batch accuracy: {:.3f}\".format(batch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641cbb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset average accuracy: 0.512\n",
      "CPU times: user 2min 6s, sys: 26.8 s, total: 2min 33s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "for i, batch in enumerate(ds.take(count=-1)):\n",
    "    trt_softmax_output = tpredict(batch['rows'])\n",
    "    batch_loss = loss.eval(batch['label'], tf.convert_to_tensor(trt_softmax_output, dtype=tf.float32)).numpy().mean()\n",
    "    total_loss = (total_loss * i + batch_loss) / (i + 1)\n",
    "    \n",
    "print(\"Dataset average accuracy: {:.3f}\".format(total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6f53b",
   "metadata": {},
   "source": [
    "## Assessing DeepConsensus accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94bacf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/train/tf-train-00000-of-00500.tfrecord.gz...\n",
      "- [1 files][  2.2 GiB/  2.2 GiB]   63.5 MiB/s                                   \n",
      "Operation completed over 1 objects/2.2 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p train\n",
    "\n",
    "gsutil cp gs://brain-genomics-public/research/deepconsensus/training-tutorial/v1.1/train/tf-train-00000-of-00500.tfrecord.gz ./train/tf-train-00000-of-00500.tfrecord.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5b72711",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"train/tf-train-00000-of-00500.tfrecord.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6ea5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_providers.get_dataset(dataset_path,\n",
    "                                num_epochs=None,\n",
    "                                batch_size=batch_size,\n",
    "                                params=params,\n",
    "                                inference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8198dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 23:01:12.788346: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 80323 of 1000000\n",
      "2023-01-25 23:01:22.787872: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 161540 of 1000000\n",
      "2023-01-25 23:01:32.788095: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 243088 of 1000000\n",
      "2023-01-25 23:01:42.787843: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 323821 of 1000000\n",
      "2023-01-25 23:01:52.787863: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 404795 of 1000000\n",
      "2023-01-25 23:02:02.787970: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 486087 of 1000000\n",
      "2023-01-25 23:02:12.788076: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 567260 of 1000000\n",
      "2023-01-25 23:02:22.787989: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 647519 of 1000000\n",
      "2023-01-25 23:02:32.788261: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 728209 of 1000000\n",
      "2023-01-25 23:02:42.787741: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 809486 of 1000000\n",
      "2023-01-25 23:02:43.812296: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset average accuracy: 1.075\n",
      "CPU times: user 1h 7min 51s, sys: 13min 34s, total: 1h 21min 25s\n",
      "Wall time: 9min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "for i, batch in enumerate(ds.take(count=-1)):\n",
    "    trt_softmax_output = tpredict(batch['rows']).astype(np.float32)\n",
    "    batch_loss = loss.eval(batch['label'], trt_softmax_output).numpy().mean()\n",
    "    total_loss = (total_loss * i + batch_loss) / (i + 1)\n",
    "    \n",
    "print(\"Dataset average accuracy: {:.3f}\".format(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf0ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
